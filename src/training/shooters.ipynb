{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "from comet_ml import ExistingExperiment\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "from librosa import display  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\n",
    "    api_key=\"IhQTOG01VFubRZ3TqW8IaWsKk\",\n",
    "    project_name=\"shooters\",\n",
    "    workspace=\"temasarkisov\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/UrbanSound8K.csv') \n",
    "labels = list(df['class'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = dict()\n",
    "for i in range(len(labels)):\n",
    "    tmp = df[df['class'] == labels[i]][:1].reset_index()\n",
    "    path = '../../data/fold{}/{}'.format(tmp['fold'][0], tmp['slice_file_name'][0])\n",
    "    files[labels[i]] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fig = plt.figure(figsize=(15,15)) # Log graphic of waveforms to Comet\n",
    "experiment.log_image('class_examples.png')\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "for i, label in enumerate(labels):\n",
    "    fn = files[label]\n",
    "    fig.add_subplot(5, 2, i+1)\n",
    "    plt.title(label)\n",
    "    data, sample_rate = librosa.load(fn)\n",
    "    librosa.display.waveplot(data, sr= sample_rate)\n",
    "plt.savefig('class_examples.png')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log graphic of waveforms to Comet\n",
    "#experiment.log_image('class_examples.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log audio files to Comet for debugging\n",
    "#for label in labels:\n",
    "#    fn = files[label]\n",
    "#    experiment.log_audio(fn, metadata = {'name': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '../../data/fold1/191431-9-0-66.wav'\n",
    "librosa_audio, librosa_sample_rate = librosa.load(fn)\n",
    "scipy_sample_rate, scipy_audio = wav.read(fn)\n",
    "print(\"Original sample rate: {}\".format(scipy_sample_rate))\n",
    "print(\"Librosa sample rate: {}\".format(librosa_sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original audio file min~max range: {} to {}'.format(np.min(scipy_audio), np.max(scipy_audio)))\n",
    "print('Librosa audio file min~max range: {0:.2f} to {0:.2f}'.format(np.min(librosa_audio), np.max(librosa_audio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Audio (note that it’s in stereo — two audio sources)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(scipy_audio)\n",
    "plt.savefig('../../img/original_audio.png')\n",
    "experiment.log_image('../../img/original_audio.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librosa: mono track\n",
    "# Librosa audio: converted to mono\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(librosa_audio)\n",
    "plt.savefig('../../img/librosa_audio.png')\n",
    "experiment.log_image('../../img/librosa_audio.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y=librosa_audio, sr=librosa_sample_rate, n_mfcc = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "librosa.display.specshow(mfccs, sr=librosa_sample_rate, x_axis='time')\n",
    "plt.savefig('../../img/MFCCs.png')\n",
    "experiment.log_image('../../img/MFCCs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple function to extract MFCCs for every file in our dataset\n",
    "def extract_features(file_name):\n",
    "  audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "  mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "  mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "     \n",
    "  return mfccs_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let’s extract features\n",
    "features = []\n",
    "# Iterate through each sound file and extract the features \n",
    "for index, row in df.iterrows():\n",
    "    file_name = os.path.join(os.path.abspath('../../data/'),'fold'+str(row[\"fold\"])+'/', str(row[\"slice_file_name\"]))  \n",
    "    try:\n",
    "        class_label = row[\"class\"]\n",
    "        data = extract_features(file_name)\n",
    "        features.append([data, class_label])\n",
    "        print(index)\n",
    "    except:\n",
    "        print(file_name, \"not found!\\n\")\n",
    "\n",
    "# Convert into a Pandas dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have successfully extracted our features from the underlying audio data, we can build and train a model\n",
    "featuresdf.iloc[0]['feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "def build_model_graph(input_shape=(40,)):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(256))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(256))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(num_labels))\n",
    "  model.add(Activation('softmax'))\n",
    "  \n",
    "  # Compile the model\n",
    "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('shooters_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 99.86%\n",
      "Testing Accuracy: 94.29%\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: {0:.2%}\".format(score[1]))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: {0:.2%}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 78,858\n",
      "Trainable params: 78,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "<class 'tensorflow.python.keras.engine.sequential.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "#accuracy = 100*score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
